 # CudaMultiGPU Documentation

[English Version](README_EN.md) | [Turkish Version](README.md)

---

## ğŸ“– About
This document explains step by step how to use the **CudaMultiGPU** class in your projects.

- Turkish documentation: [README.md](README.md)  
- English documentation: [README_EN.md](README_EN.md)

---


# CudaMultiGPU KullanÄ±m DokÃ¼manÄ±

Bu dokÃ¼man, projelerinizde **CudaMultiGPU** sÄ±nÄ±fÄ±nÄ±n nasÄ±l kullanÄ±lacaÄŸÄ±nÄ± adÄ±m adÄ±m anlatmaktadÄ±r.

---

## 1. SÄ±nÄ±fÄ± Projeye Ekleme

`gpu_utils.py` dosyasÄ±nÄ± proje kÃ¶k dizininize kopyalayÄ±n.  
Kodunuzda sÄ±nÄ±fÄ± iÃ§e aktarÄ±n:

<img width="468" height="45" alt="image" src="https://github.com/user-attachments/assets/98f5ad01-c035-44d1-b97a-30abb18883ab" />


```python
from gpu_utils import CudaMultiGPU
```

---

## 2. DEVICE TanÄ±mlamasÄ±nÄ± KaldÄ±r

Kodunuzdan `DEVICE` tanÄ±mÄ±nÄ± kaldÄ±rÄ±n.

<img width="468" height="46" alt="image" src="https://github.com/user-attachments/assets/96a89fe6-c05b-49d7-94e3-b2fe274fe525" />


---

## 3. Modeli Sarmalama

Mevcut PyTorch modelinizi Ã§oklu GPU desteÄŸiyle kullanmak iÃ§in:

<img width="468" height="51" alt="image" src="https://github.com/user-attachments/assets/bacfc348-752e-4fc6-9bd8-7fbaa56a91fc" />


```python
model = MyModel()              # mevcut PyTorch modeliniz
model = CudaMultiGPU(model)    # tÃ¼m CUDA aygÄ±tlarÄ±nÄ± algÄ±lar ve DataParallel ile sarar
DEVICE = model.device          # verilerin taÅŸÄ±nacaÄŸÄ± aygÄ±t
```

- CUDA aygÄ±tÄ± yoksa model otomatik olarak **CPU** Ã¼zerinde Ã§alÄ±ÅŸÄ±r.  
- `CudaMultiGPU` Ã¶rneÄŸi Ã§aÄŸrÄ±labilir olduÄŸundan ÅŸu ÅŸekilde kullanÄ±labilir:  

```python
outputs = model(input_tensor)
```

- Altta yatan modele doÄŸrudan eriÅŸmek iÃ§in:

```python
model.model
```

---

## 4. Optimizasyonu Ayarlama

`CudaMultiGPU`, alttaki modele Ã¶zellik ve metotlarÄ± ilettiÄŸi iÃ§in parametrelere doÄŸrudan eriÅŸilebilir:

<img width="468" height="28" alt="image" src="https://github.com/user-attachments/assets/d590b533-1c83-4bc5-95c7-63ec67d224b5" />


```python
optimizer = torch.optim.Adam(model.model.parameters(), lr=1e-4)
```

---

## 5. EÄŸitim DÃ¶ngÃ¼sÃ¼nde YapÄ±lacak DeÄŸiÅŸiklikler

<img width="468" height="77" alt="image" src="https://github.com/user-attachments/assets/259c951c-3875-4c90-8e6b-7934eb350319" />


### Verileri DoÄŸru AygÄ±ta TaÅŸÄ±ma
```python
inputs  = inputs.to(DEVICE)
targets = targets.to(DEVICE)
```

### Modeli Ã‡aÄŸÄ±rma
```python
outputs = model(inputs)
```

### Loss OrtalamasÄ±
`DataParallel`, her GPU iÃ§in ayrÄ± loss dÃ¶ndÃ¼rebilir.  
Geri yayÄ±lÄ±m iÃ§in ortalama alÄ±nmalÄ±dÄ±r:

```python
loss = outputs.loss.mean()  # veya benzer ÅŸekilde hesaplanan loss.mean()
```

### Geri YayÄ±lÄ±m ve Optimizasyon
```python
loss.backward()
optimizer.step()
optimizer.zero_grad()
```

---

## 6. Batch Size ve Num Workers Ayarlama

<img width="297" height="152" alt="image" src="https://github.com/user-attachments/assets/057fd002-eb19-4de8-bf8b-2bb5f9dbe1f0" />


Bilgisayarda kullanÄ±lan ekran kartÄ± sayÄ±sÄ±na ve yapÄ±lan deneyin iÅŸlem kapasitesine gÃ¶re `batch_size` deÄŸeri **128â€“256** aralÄ±ÄŸÄ±nda yÃ¼kseltilebilir.  

**num_workers** iÃ§in Ã¶nerilen hesaplama ÅŸu ÅŸekildedir:

```
num_workers = CPU Ã§ekirdek sayÄ±sÄ± / GPU sayÄ±sÄ±
```

### Pratik Ã–neriler:
- 16 Ã§ekirdekli CPU ve 3 GPU â†’ `num_workers = 4â€“6`  
- 32 Ã§ekirdekli CPU ve 3 GPU â†’ `num_workers = 8â€“12`  
- 64 Ã§ekirdekli CPU (Threadripper / EPYC gibi) â†’ `num_workers = 16+`  

GPU kullanÄ±mÄ± gÃ¶zlemlenerek deÄŸerler gerektiÄŸinde daha da yÃ¼kseltilebilir.

---

## Lisans
Bu dokÃ¼man ve `CudaMultiGPU` sÄ±nÄ±fÄ±, kendi projelerinizde Ã¶zgÃ¼rce kullanÄ±labilir.
